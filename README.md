# Deep Learning Specialization

This repository contains materials and lab assignments for the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by [Andrew Ng](https://www.andrewng.org/), organized into five comprehensive courses:

## Course 1: Neural Networks and Deep Learning
**[Go to Course 1 on Coursera](https://www.coursera.org/learn/neural-networks-deep-learning)**

### Week 1: Introduction to Deep Learning
- **Topics Covered:**
  - What is a neural network?
  - Supervised learning with neural networks
  - Why is deep learning taking off?
- **Heroes of Deep Learning:** [Geoffrey Hinton](https://youtu.be/-eyhCTvrEtE)

### Week 2: Neural Networks Basics
- **Topics Covered:**
  - Binary classification
  - Logistic regression
  - Gradient descent
  - Python and vectorization
- **Heroes of Deep Learning:** [Pieter Abbeel](https://youtu.be/dmkPJpWCVcI)

### Week 3: Shallow Neural Networks
- **Topics Covered:**
  - Neural network representation
  - Computing neural network output
  - Vectorizing across multiple examples
  - Activation functions
- **Heroes of Deep Learning:** [Ian Goodfellow](https://youtu.be/pWAc9B2zJS4)

### Week 4: Deep Neural Networks
- **Topics Covered:**
  - Deep L-layer neural network
  - Forward and backward propagation
  - Building blocks of deep neural networks
  - Parameters vs hyperparameters

## Course 2: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization
**[Go to Course 2 on Coursera](https://www.coursera.org/learn/deep-neural-network)**

### Week 1: Practical Aspects of Deep Learning
- **Topics Covered:**
  - Setting up your Machine Learning Application
  - Regularization techniques (L2, Dropout, Data Augmentation, Early Stopping)
  - Setting up your optimization problem
  - Normalizing inputs
  - Vanishing/Exploding gradients
  - Weight initialization
  - Gradient checking
- **Heroes of Deep Learning:** [Yoshua Bengio](https://youtu.be/pnTLZQhFpaE)

### Week 2: Optimization Algorithms
- **Topics Covered:**
  - Mini-batch gradient descent
  - Exponentially weighted averages
  - Momentum and RMSprop
  - Adam optimization algorithm
  - Learning rate decay
  - The problem of local optima
- **Heroes of Deep Learning:** [Yuanqing Lin](https://youtu.be/3GfOnI3goAk)

### Week 3: Hyperparameter Tuning, Batch Normalization and Programming Frameworks
- **Topics Covered:**
  - Hyperparameter tuning
  - Batch normalization
  - Multi-class classification
  - Programming frameworks (TensorFlow, PyTorch)
  - TensorFlow implementation

## Course 3: Structuring your Machine Learning Project
**[Go to Course 3 on Coursera](https://www.coursera.org/learn/machine-learning-projects)**

### Week 1: ML Strategy (1)
- **Topics Covered:**
  - Orthogonalization
  - Single number evaluation metric
  - Satisficing and optimizing metric
  - Training, development, and test distributions
  - Size of the development and test sets
  - When to change development/test sets and metrics
  - Why human-level performance?
  - Avoidable bias
  - Understanding human-level performance
  - Surpassing human-level performance
  - Improving your model performance
- **Heroes of Deep Learning:** [Andrej Karpathy](https://youtu.be/_au3yw46lcg)

### Week 2: ML Strategy (2)
- **Topics Covered:**
  - Build system quickly
  - Training and testing on different distributions
  - Bias and variance with mismatched data distributions
  - Addressing data mismatch
  - Transfer learning
  - Multi-task learning
  - What is end-to-end deep learning?
  - Whether to use end-to-end deep learning
- **Heroes of Deep Learning:** [Ruslan Salakhutdinov](https://youtu.be/EveYfHKXvfc)

## Course 4: Convolutional Neural Networks
**[Go to Course 4 on Coursera](https://www.coursera.org/learn/convolutional-neural-networks)**

### Week 1: Foundations of Convolutional Neural Networks
- **Topics Covered:**
  - Computer vision applications
  - Edge detection examples
  - More edge detection
  - Padding
  - Strided convolutions
  - Convolutions over volumes
  - One layer of a convolutional network
  - Simple convolutional network example
  - Pooling layers
  - CNN example
  - Why convolutions?
- **Heroes of Deep Learning:** [Yann LeCun](https://youtu.be/JS12eb1cTLE)

### Week 2: Deep Convolutional Models: Case Studies
- **Topics Covered:**
  - Why look at case studies?
  - Classic networks (LeNet-5, AlexNet, VGG)
  - ResNets (Residual Networks)
  - Why ResNets work?
  - Networks in Networks and 1x1 convolutions
  - Inception network motivation
  - Inception network
  - Using open-source implementations
  - Transfer learning
  - Data augmentation
  - State of computer vision

### Week 3: Object Detection
- **Topics Covered:**
  - Object localization
  - Landmark detection
  - Object detection
  - Convolutional implementation of sliding windows
  - Bounding box predictions
  - Intersection over Union
  - Non-max suppression
  - Anchor boxes
  - YOLO algorithm
  - Region proposals (R-CNN)

### Week 4: Special Applications: Face Recognition & Neural Style Transfer
- **Topics Covered:**
  - What is face recognition?
  - One-shot learning
  - Siamese network
  - Triplet loss
  - Face verification and binary classification
  - What is neural style transfer?
  - What are deep ConvNets learning?
  - Cost function
  - Content cost function
  - Style cost function
  - 1D and 3D generalizations of models

## Course 5: Natural Language Processing: Building Sequence Models
**[Go to Course 5 on Coursera](https://www.coursera.org/learn/nlp-sequence-models)**

---

## Getting Started
1. Clone this repository.
2. Open the desired course folder and navigate to the lab assignments.
3. Launch the Jupyter Notebooks to begin working through the labs.

## Requirements
- Python 3.x
- Jupyter Notebook
- Common DL libraries: numpy, matplotlib, tensorflow, keras, etc.

## License
This repository is for educational purposes only. 
